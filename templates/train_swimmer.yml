drl_class: 'PPO'
baseline: False
train-iterations: 3000 #3000

drl_config: 
    env: SwimmerSurrogate
    env_config:
        dyn_model: null # None
        max_episode_steps: 1000
        mod_angles: True
        reset_on_bounds: True
 
    framework: torch
    evaluation_config:
        env_config:
            dyn_model: null # None
            max_episode_steps: 1000
            mod_angles: False
            reset_on_bounds: False
        explore: False
    evaluation_interval: 1
    evaluation_duration: 10


# Ray Configs
ray_config:
    run_config:
        stop:
            # timesteps_total
            num_env_steps_sampled: 1.2e+6
        log_to_file: True 
    tune_config:
        num_samples: 20 # number of sample trials to run
    checkpoint_freq: 50


# SINDy Configs
init_collection:
    collect_seed: 0 
    n_random_steps: 16000
    n_null_steps: 0
    max_traj_len: 100

sindy_fit:
    fit_freq: 10 # how many training iterations to perform before fitting

dyn_model_config:
    affine_config: 
        poly_deg: 2
        n_state: 8 
        n_control: 2
        poly_int: False
        tensor: True
    base_config:
        threshold: 0.02 
        alpha: 0.5
    ensemble_config:
        bagging: True 
        library_ensemble: True
        n_models: 100